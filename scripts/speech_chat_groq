import tkinter as tk
from tkinter import filedialog, messagebox, scrolledtext
import threading
import sounddevice as sd
import numpy as np
import queue
import tempfile
import json
import re
import os
import toml
from gtts import gTTS
from google.cloud import speech
import docx
import PyPDF2
from tkinter import ttk
from ttkthemes import ThemedTk
from datetime import datetime
import time
import requests
from requests.exceptions import RequestException
import urllib3
from urllib3.exceptions import InsecureRequestWarning
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Disable SSL verification warning
urllib3.disable_warnings(InsecureRequestWarning)

# Get the directory of the current script
script_dir = os.path.dirname(os.path.abspath(__file__))

# Construct the path to secrets.toml
secrets_path = os.path.join(script_dir, '..', 'secrets.toml')

# Load secrets from the secrets.toml
try:
    with open(secrets_path, 'r') as f:
        secrets = toml.load(f)
except FileNotFoundError:
    print(f"Error: secrets.toml not found at {secrets_path}")
    print("Please ensure the secrets.toml file exists in the correct location.")
    exit(1)

# Set up Groq API key
GROQ_API_KEY = secrets["GROQ_API_KEY"]

# Create a temporary file with the Google Cloud credentials
google_cloud_credentials = secrets["gcp_service_account"]
with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as temp_file:
    json.dump(google_cloud_credentials, temp_file)
    temp_file_path = temp_file.name

# Set the environment variable to the path of the temporary file
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = temp_file_path

# Initialize Google Speech-to-Text client and queue
client_speech = speech.SpeechClient()
audio_queue = queue.Queue()

class AudioLevelMeter(tk.Canvas):
    def __init__(self, master, device_index, **kwargs):
        super().__init__(master, **kwargs)
        self.device_index = device_index
        self.levels = [0] * 20
        self.configure(bg="#2E2E2E")  # Set a dark background for the meter
        self.create_rectangles()
        self.update_meter()

    def create_rectangles(self):
        self.bars = []
        for i in range(20):
            bar = self.create_rectangle(i * 15 + 5, 20, i * 15 + 15, 80, fill="gray", outline="")
            self.bars.append(bar)

    def update_meter(self):
        # Get the current audio input level
        level = self.get_input_level()
        # Update the level bars based on the current level
        self.update_bars(level)
        # Schedule the next update
        self.after(100, self.update_meter)  # Update every 100ms

    def update_bars(self, level):
        # Normalize level to 0-20 range
        num_active_bars = int(level / 2)  # Adjust this factor to make the meter more sensitive
        for i, bar in enumerate(self.bars):
            if i < num_active_bars:
                self.itemconfig(bar, fill="green")
            else:
                self.itemconfig(bar, fill="gray")

    def get_input_level(self):
        duration = 0.1  # duration to measure level (100ms)
        recording = sd.rec(int(duration * 44100), samplerate=44100, channels=1, device=self.device_index)
        sd.wait()
        rms = np.sqrt(np.mean(recording ** 2))
        return rms * 1000  # Increase the multiplier to make the meter more sensitive


class SpeechApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Speech-Enabled Chat with Groq")
        self.root.geometry("1000x800")
        self.is_waiting_for_response = False
        self.is_speaking = False
        self.dark_mode = False
        self.volume = 1.0

        # Initialize style
        self.style = ttk.Style(self.root)
        self.style.theme_use('arc')

        self.context = ""
        self.chat_history = [{"role": "system", "content": "Context not set."}]
        self.stop_signal = False
        self.uploaded_files = []
        self.lock = threading.Lock()

        # Initialize device list and names
        self.device_list = sd.query_devices()
        self.device_names = [device['name'] for device in self.device_list]

        self.setup_gui()
        self.apply_theme()

    def setup_gui(self):
        self.style = ttk.Style()
        self.style.theme_use('arc')

        # Main frame
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.pack(fill=tk.BOTH, expand=True)

        # Top frame (API Test, Mic Check, Dark Mode Toggle)
        top_frame = ttk.Frame(main_frame, padding="5")
        top_frame.pack(fill=tk.X)

        self.device_var = tk.StringVar(self.root)
        if self.device_names:  # Check if device_names is not empty
            self.device_var.set(self.device_names[0])
        else:
            print("Warning: No audio devices found.")
            self.device_var.set("No devices available")

        self.device_menu = ttk.Combobox(top_frame, textvariable=self.device_var,
                                        values=self.device_names, state="readonly", width=30)
        self.device_menu.pack(side=tk.LEFT, padx=5)

        self.test_api_button = ttk.Button(top_frame, text="Test APIs", command=self.test_apis)
        self.test_api_button.pack(side=tk.LEFT, padx=5)

        self.dark_mode_button = ttk.Button(top_frame, text="Toggle Dark Mode", command=self.toggle_dark_mode)
        self.dark_mode_button.pack(side=tk.RIGHT, padx=5)

        # Audio level meter
        self.audio_level_meter = AudioLevelMeter(top_frame, device_index=self.device_names.index(self.device_var.get()),
                                                 width=310, height=100)
        self.audio_level_meter.pack(side=tk.LEFT, padx=5)

        # Middle frame (Context & File Upload)
        middle_frame = ttk.Frame(main_frame, padding="5")
        middle_frame.pack(fill=tk.BOTH, expand=True)

        self.job_label = ttk.Label(middle_frame, text="Job Context:", font=('Arial', 12, 'bold'))
        self.job_label.pack(anchor='w', padx=5)

        self.job_input = scrolledtext.ScrolledText(middle_frame, width=80, height=5, wrap=tk.WORD, font=('Arial', 12))
        self.job_input.pack(fill=tk.X, padx=5, pady=5)

        self.context_label = ttk.Label(middle_frame, text="General Context:", font=('Arial', 12, 'bold'))
        self.context_label.pack(anchor='w', padx=5)

        self.context_input = scrolledtext.ScrolledText(middle_frame, width=80, height=5, wrap=tk.WORD,
                                                       font=('Arial', 12))
        self.context_input.pack(fill=tk.X, padx=5, pady=5)

        # Prepopulate the General Context field with the default context
        default_system_message = (
            "You are an AI assistant designed to help with answering difficult questions during job interviews. "
            "Your primary objectives are:\n"
            "1. **Behavioral Questions (e.g., 'Tell me about a time when...')**:\n"
            "  - When asked a behavioral question, generate a model answer using specific examples.\n"
            "  - Structure your response in bullet points, detailing:\n"
            "    - **The Situation**: Describe the situation or challenge.\n"
            "    - **The Task**: Explain what needed to be done.\n"
            "    - **The Action**: Detail the actions taken.\n"
            "    - **The Result**: Highlight the outcomes or achievements.\n"
            "2. **General and Motivational Questions (e.g., 'Why do you want to join our company?')**:\n"
            "  - Craft precise and compelling responses, integrating relevant information from the job description "
            "    and context provided. Emphasize alignment between the user's experience and the role or company.\n"
            "Always provide thoughtful, detailed, and contextually relevant responses."
        )
        self.context_input.insert(tk.END, default_system_message)

        # Resume Input
        self.resume_label = ttk.Label(middle_frame, text="Resume:", font=('Arial', 12, 'bold'))
        self.resume_label.pack(anchor='w', padx=5)

        self.resume_input = scrolledtext.ScrolledText(middle_frame, width=80, height=10, wrap=tk.WORD, font=('Arial', 12))
        self.resume_input.pack(fill=tk.X, padx=5, pady=5)

        # Bottom frame (Chat)
        bottom_frame = ttk.Frame(main_frame, padding="5")
        bottom_frame.pack(fill=tk.BOTH, expand=True)

        button_frame = ttk.Frame(bottom_frame)
        button_frame.pack(fill=tk.X)

        self.start_button = ttk.Button(button_frame, text="Start Recording", command=self.start_recording)
        self.start_button.pack(side=tk.LEFT, padx=5)

        self.stop_button = ttk.Button(button_frame, text="Stop Recording", command=self.stop_recording)
        self.stop_button.pack(side=tk.LEFT, padx=5)

        self.clear_button = ttk.Button(button_frame, text="Clear Chat", command=self.clear_chat)
        self.clear_button.pack(side=tk.LEFT, padx=5)

        self.speaking_indicator = ttk.Label(button_frame, text="â—", foreground="grey")
        self.speaking_indicator.pack(side=tk.LEFT, padx=5)

        # Transcript Display (iMessage Style)
        self.transcript_display = scrolledtext.ScrolledText(bottom_frame, height=20, width=80, wrap=tk.WORD,
                                                            font=('Arial', 12))
        self.transcript_display.pack(fill=tk.BOTH, expand=True)
        self.transcript_display.tag_configure("user", foreground="white", background="#007AFF", justify="right",
                                              font=('Arial', 12, 'bold'), lmargin1=10, rmargin=10)
        self.transcript_display.tag_configure("assistant", foreground="black", background="#E5E5EA", justify="left",
                                              font=('Arial', 12), lmargin1=10, rmargin=10)
        self.transcript_display.tag_configure("timestamp", foreground="gray", font=('Arial', 10, 'italic'))

        # Loading indicator
        self.loading_label = ttk.Label(bottom_frame, text="", font=('Arial', 12, 'italic'))
        self.loading_label.pack()

        self.root.after_idle(self.root.update_idletasks)

        # Set up custom styles for dark mode compatibility
        self.style.configure("Custom.Treeview", rowheight=25)
        self.style.configure("Custom.TCombobox", selectbackground='#0078D7', selectforeground='white')
        self.style.configure("Custom.TButton", padding=5)
        self.style.configure("Custom.TEntry", fieldbackground="white", foreground="black")
        self.style.configure("Custom.TCombobox", fieldbackground="white", foreground="black",
                             selectbackground='#0078D7', selectforeground='white')
        self.style.configure("Custom.Treeview", fieldbackground="white", background="white", foreground="black")
        self.style.map('Custom.Treeview', background=[('selected', '#0078D7')], foreground=[('selected', 'white')])

    def apply_theme(self):
        bg_color = "#2E2E2E" if self.dark_mode else "white"
        fg_color = "white" if self.dark_mode else "black"
        button_fg_color = "black"  # Set button text color to black in dark mode
        entry_bg = "#3E3E3E" if self.dark_mode else "white"
        entry_fg = "white" if self.dark_mode else "black"
        entry_border_color = "white"  # Add a white border for the text boxes

        self.root.configure(bg=bg_color)
        self.style.configure("TFrame", background=bg_color)
        self.style.configure("TLabel", background=bg_color, foreground=fg_color)
        self.style.configure("Custom.TButton", background=bg_color, foreground=button_fg_color)
        self.style.configure("Custom.TEntry", fieldbackground=entry_bg, foreground=entry_fg,
                             bordercolor=entry_border_color)
        self.style.configure("Custom.TCombobox", fieldbackground=entry_bg, foreground=entry_fg,
                             selectbackground='#0078D7', selectforeground='white')
        self.style.configure("Custom.Treeview", fieldbackground=entry_bg, background=entry_bg, foreground=fg_color)
        self.style.map('Custom.Treeview', background=[('selected', '#0078D7')], foreground=[('selected', 'white')])

        self.transcript_display.configure(bg=entry_bg, fg=fg_color, insertbackground=fg_color, bd=2, relief="solid",
                                          highlightbackground=entry_border_color)
        self.job_input.configure(bg=entry_bg, fg=fg_color, insertbackground=fg_color, bd=2, relief="solid",
                                 highlightbackground=entry_border_color)
        self.context_input.configure(bg=entry_bg, fg=fg_color, insertbackground=fg_color, bd=2, relief="solid",
                                     highlightbackground=entry_border_color)
        self.resume_input.configure(bg=entry_bg, fg=fg_color, insertbackground=fg_color, bd=2, relief="solid",
                                    highlightbackground=entry_border_color)

        self.transcript_display.tag_configure("user", foreground="white",
                                              background="#0056b3" if self.dark_mode else "#007AFF")
        self.transcript_display.tag_configure("assistant", foreground="black",
                                              background="#4a4a4a" if self.dark_mode else "#E5E5EA")
        self.transcript_display.tag_configure("timestamp", foreground="#b0b0b0" if self.dark_mode else "gray")

        for widget in [self.test_api_button, self.dark_mode_button, self.start_button, self.stop_button, self.clear_button]:
            widget.configure(style="Custom.TButton")

        self.device_menu.configure(style="Custom.TCombobox")

    def toggle_dark_mode(self):
        self.dark_mode = not self.dark_mode
        self.apply_theme()
        bg_color = "#2E2E2E" if self.dark_mode else "white"
        fg_color = "white" if self.dark_mode else "black"

        # Configure root and style
        self.root.configure(bg=bg_color)
        self.style.configure("TFrame", background=bg_color)
        self.style.configure("TLabel", background=bg_color, foreground=fg_color)
        self.style.configure("TButton", background=bg_color, foreground=fg_color)

        # Configure text widgets
        self.transcript_display.configure(bg=bg_color, fg=fg_color)
        self.job_input.configure(bg=bg_color, fg=fg_color, insertbackground=fg_color)
        self.context_input.configure(bg=bg_color, fg=fg_color, insertbackground=fg_color)
        self.resume_input.configure(bg=bg_color, fg=fg_color, insertbackground=fg_color)

        # Reconfigure chat message tags
        self.transcript_display.tag_configure("user", foreground="white",
                                              background="#0056b3" if self.dark_mode else "#007AFF")
        self.transcript_display.tag_configure("assistant", foreground="black",
                                              background="#4a4a4a" if self.dark_mode else "#E5E5EA")
        self.transcript_display.tag_configure("timestamp", foreground="#b0b0b0" if self.dark_mode else "gray")

        # Update loading label
        self.loading_label.configure(foreground=fg_color)

    def test_apis(self):
        try:
            # Test Google Speech-to-Text API with a minimal configuration
            client = speech.SpeechClient()

            # Using a sample audio file from Google Cloud Storage for the test
            audio = speech.RecognitionAudio(uri="gs://cloud-samples-data/speech/brooklyn_bridge.raw")
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=16000,
                language_code="en-US",
            )

            response = client.recognize(config=config, audio=audio)

            if response:
                print("Google Speech-to-Text API connection successful.")
            else:
                raise Exception("Failed to get a valid response from Google Speech-to-Text API")

            # Test Groq API
            headers = {
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            }
            data = {
                "model": "mixtral-8x7b-32768",
                "messages": [{"role": "user", "content": "Hello, Groq!"}],
                "temperature": 0.7,
                "max_tokens": 100
            }
            response = requests.post("https://api.groq.com/openai/v1/chat/completions", headers=headers, json=data, verify=False)
            if response.status_code == 200:
                print("Groq API connection successful.")
            else:
                raise Exception(f"Failed to get a valid response from Groq API. Status code: {response.status_code}")

            messagebox.showinfo("Success", "Successfully connected to Google Speech-to-Text & Groq APIs.")
        except Exception as e:
            messagebox.showerror("Error", f"API Connection Test Failed: {str(e)}")

    def start_recording(self):
        self.stop_signal = False
        self.initial_context = self.prepare_initial_context()
        self.chat_history = []
        threading.Thread(target=self.listen_and_transcribe, daemon=True).start()

    def clear_chat(self):
        self.transcript_display.delete(1.0, tk.END)
        self.chat_history = [{"role": "system", "content": "Context not set."}]
    
    def get_resume_content(self):
        return self.resume_input.get("1.0", tk.END).strip()

    def is_behavioral_question(self, text):
        behavioral_patterns = [
            r"tell me about a time when",
            r"describe a situation where",
            r"give me an example of",
            r"how did you handle",
            r"what do you do when",
        ]
        return any(re.search(pattern, text.lower()) for pattern in behavioral_patterns)

    def prepare_initial_context(self):
        context = self.context_input.get("1.0", tk.END).strip()
        job_context = self.job_input.get("1.0", tk.END).strip()
        self.resume_content = self.get_resume_content()

        system_message = f"Job Context: {job_context}\nGeneral Context: {context}\n\n"
        system_message += f"Resume Content:\n{self.resume_content}\n\n"

        system_message += (
            "For behavioral questions, structure your response as follows:\n"
            "- **Situation**: Describe the situation or challenge.\n"
            "- **Task**: Explain what needed to be done.\n"
            "- **Action**: Detail the actions taken.\n"
            "- **Result**: Highlight the outcomes or achievements."
        )

        return {"role": "system", "content": system_message}

    def prepare_behavioral_prompt(self, query):
        prompt = f"""
        Behavioral Question: {query}

        Resume Content:
        {self.resume_content}

        Based on the provided resume and the context of this person's experience, prepare a model answer for the behavioral question. The answer should:
        1. Be anchored in the specific experiences mentioned in the resume
        2. Follow the STAR (Situation, Task, Action, Result) format
        3. Be detailed and specific, using concrete examples from the person's background
        4. Be approximately 250-300 words long

        Please structure the response as follows:
        - Situation: [Brief description of the context]
        - Task: [What needed to be done]
        - Action: [Steps taken to address the situation]
        - Result: [Outcome and lessons learned]

        Provide a well-crafted response that showcases the individual's skills and experiences relevant to the question.
        """
        return prompt

    def stop_recording(self):
        self.stop_signal = True
        try:
            audio_queue.put(None)
        except Exception as e:
            messagebox.showerror("Error", f"Error stopping recording: {str(e)}")

    def listen_and_transcribe(self):
        selected_device = self.device_var.get()
        device_index = self.device_names.index(selected_device)

        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=44100,
            language_code="en-US",
            max_alternatives=1,
            enable_automatic_punctuation=True,
        )

        streaming_config = speech.StreamingRecognitionConfig(
            config=config,
            interim_results=True,
            single_utterance=False
        )

        def audio_callback(indata, frames, time, status):
            if status:
                print(f"Audio callback status: {status}")
            audio_queue.put(indata.copy())

        def audio_generator():
            while not self.stop_signal:
                try:
                    chunk = audio_queue.get(block=True, timeout=0.1)
                    if chunk is None:  # Check for stop signal
                        break
                    audio_data = (chunk * 32767).astype(np.int16).tobytes()
                    yield speech.StreamingRecognizeRequest(audio_content=audio_data)
                except queue.Empty:
                    continue

        try:
            with sd.InputStream(samplerate=44100, channels=1, callback=audio_callback, device=device_index,
                                latency='low',
                                blocksize=1024):
                requests = audio_generator()
                responses = client_speech.streaming_recognize(streaming_config, requests=requests)

                for response in responses:
                    if self.stop_signal:
                        print("Stop signal received, breaking loop")
                        break
                    for result in response.results:
                        if result.is_final:
                            transcribed_text = result.alternatives[0].transcript
                            print(f"New transcribed text: {transcribed_text}")
                            self.transcript_display.insert(tk.END, f"You: {transcribed_text}\n", "user")
                            self.transcript_display.see(tk.END)

                            if self.is_question(transcribed_text):
                                print(f"Question detected: {transcribed_text}")
                                if not self.is_waiting_for_response:
                                    print("Starting to process GPT response")
                                    self.is_waiting_for_response = True
                                    threading.Thread(target=self.process_gpt_response, args=(transcribed_text,)).start()
                                else:
                                    print("Waiting for previous response, skipping question")

        except Exception as e:
            messagebox.showerror("Error", f"Error during transcription: {str(e)}")

        print("Exiting listen_and_transcribe")

    def is_question(self, text):
        """Determine if the text is a question or a behavioral query."""
        question_words = ["who", "what", "where", "when", "why", "how", "is", "are", "do", "does", "can", "could",
                          "would", "should", "tell me about"]
        return text.strip().endswith("?") or text.lower().startswith(tuple(question_words))

    def groq_api_request(self, endpoint, data):
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # Create a session with retry mechanism
        session = requests.Session()
        retries = Retry(total=3, backoff_factor=0.5, status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))
        
        try:
            response = session.post(f"https://api.groq.com/openai/v1/{endpoint}", headers=headers, json=data, verify=False, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"Error in Groq API request: {e}")
            raise

    def ask_groq(self, query):
        print(f"Asking Groq: {query}")
        max_retries = 3
        backoff_factor = 0.5

        for attempt in range(max_retries):
            try:
                if self.is_behavioral_question(query):
                    behavioral_prompt = self.prepare_behavioral_prompt(query)
                    messages = [
                        {"role": "system", "content": self.initial_context["content"]},
                        {"role": "user", "content": behavioral_prompt}
                    ]
                else:
                    self.chat_history.append({"role": "user", "content": query})
                    messages = [self.initial_context] + self.chat_history[-5:]

                data = {
                    "model": "mixtral-8x7b-32768",
                    "messages": messages,
                    "temperature": 0.7,
                    "max_tokens": 500
                }

                response_json = self.groq_api_request("chat/completions", data)
                response_text = response_json['choices'][0]['message']['content'].strip()
                self.chat_history.append({"role": "assistant", "content": response_text})
                print(f"Groq response received, length: {len(response_text)}")
                return response_text

            except RequestException as e:
                print(f"RequestException in ask_groq (attempt {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    return "I'm sorry, but I'm having trouble connecting right now. Please try again in a moment."
                time.sleep(backoff_factor * (2 ** attempt))  # Exponential backoff
            except Exception as e:
                print(f"Unexpected error in ask_groq: {e}")
                return "An unexpected error occurred. Please try again."

    def display_message(self, sender, message, tag):
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.transcript_display.insert(tk.END, f"[{timestamp}] ", "timestamp")
        self.transcript_display.insert(tk.END, f"{sender}: {message}\n", tag)
        self.transcript_display.see(tk.END)

    def process_gpt_response(self, query):
        try:
            print(f"Processing GPT response for query: {query}")
            self.loading_label.config(text="Processing...")
            self.root.update_idletasks()
            response_text = self.ask_groq(query)
            print(f"Received response from Groq: {response_text[:50]}...")  # Print first 50 chars of response
            self.display_message("Assistant", response_text, "assistant")
            self.speak_text(response_text)
        except Exception as e:
            print(f"Error in Groq response: {str(e)}")
            messagebox.showerror("Error", f"Error in Groq response: {str(e)}")
        finally:
            print("Resetting is_waiting_for_response flag")
            self.is_waiting_for_response = False
            self.loading_label.config(text="")
            self.root.update_idletasks()

    def speak_text(self, text):
        self.is_speaking = True
        self.speaking_indicator.config(foreground="red")
        tts = gTTS(text=text, lang='en')
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_mp3_file:
            tts.save(temp_mp3_file.name)
            temp_mp3_file_path = temp_mp3_file.name

        if os.name == 'posix':  # macOS/Linux
            os.system(f"afplay {temp_mp3_file_path}")
        elif os.name == 'nt':  # Windows
            os.system(f"start {temp_mp3_file_path}")

        self.is_speaking = False
        self.speaking_indicator.config(foreground="grey")

# Run the application
if __name__ == "__main__":
    root = ThemedTk(theme="arc")  # Using a modern theme
    app = SpeechApp(root)
    root.mainloop()
